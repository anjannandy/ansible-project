---
# ===== COMPREHENSIVE HADOOP ECOSYSTEM SETUP =====
- name: Complete Hadoop Ecosystem Setup using Scripts - Serial Execution with Retry
  hosts: hadoop
  become: no
  gather_facts: yes
  serial: 1  # Process one server at a time
  vars:
    # Core versions
    hadoop_version: "3.3.6"
    java_version: "11"
    
    # Processing engines
    spark_version: "3.5.0"
    flink_version: "1.18.0"
    
    # Data warehousing & SQL
    hive_version: "3.1.3"
    presto_version: "0.281"
    drill_version: "1.21.1"
    
    # NoSQL databases
    hbase_version: "2.5.5"
    cassandra_version: "4.1.3"
    mongodb_version: "7.0"
    
    # Streaming & messaging
    kafka_version: "2.13-3.5.1"
    nifi_version: "1.23.2"
    storm_version: "2.5.0"
    
    # Coordination & management
    zookeeper_version: "3.8.2"
    ambari_version: "2.7.5"
    
    # Data ingestion & ETL
    sqoop_version: "1.4.7"
    flume_version: "1.11.0"
    
    # Machine Learning
    mahout_version: "14.1"
    
    # Search & indexing
    solr_version: "9.4.0"
    elasticsearch_version: "8.11.0"
    
    # Workflow management
    oozie_version: "5.2.1"
    airflow_version: "2.7.3"
    
    # Monitoring & metrics
    ganglia_version: "3.7.2"
    
    # Installation paths
    hadoop_home: "/opt/hadoop"
    spark_home: "/opt/spark"
    flink_home: "/opt/flink"
    hive_home: "/opt/hive"
    presto_home: "/opt/presto"
    drill_home: "/opt/drill"
    hbase_home: "/opt/hbase"
    cassandra_home: "/opt/cassandra"
    kafka_home: "/opt/kafka"
    nifi_home: "/opt/nifi"
    storm_home: "/opt/storm"
    zookeeper_home: "/opt/zookeeper"
    sqoop_home: "/opt/sqoop"
    flume_home: "/opt/flume"
    mahout_home: "/opt/mahout"
    solr_home: "/opt/solr"
    elasticsearch_home: "/opt/elasticsearch"
    oozie_home: "/opt/oozie"
    
    # Configuration
    max_retries: 3
    script_dir: "/home/ubuntu/hadoop-scripts"
    state_dir: "/var/lib/hadoop-setup-state"
    log_dir: "/home/ubuntu/hadoop-setup-logs"
    namenode_host: "{{ groups['namenode'][0] }}"
    resourcemanager_host: "{{ groups['resourcemanager'][0] if groups['resourcemanager'] is defined else groups['namenode'][0] }}"
    hbase_master_host: "{{ groups['hbase_master'][0] if groups['hbase_master'] is defined else groups['namenode'][0] }}"

  tasks:
    - name: "Display current server being processed"
      debug:
        msg: "Processing Hadoop Ecosystem setup on {{ inventory_hostname }} ({{ ansible_host }}) - Role: {{ node_role }}"

    - name: "Create local log directory"
      delegate_to: localhost
      become: no
      file:
        path: "./logs"
        state: directory
        mode: '0755'
      run_once: true

    - name: "Create script directory on remote host"
      file:
        path: "{{ script_dir }}"
        state: directory
        mode: '0755'
        owner: ubuntu
        group: ubuntu

    - name: "Copy setup scripts to remote host"
      copy:
        src: "scripts/{{ item }}"
        dest: "{{ script_dir }}/{{ item }}"
        mode: '0755'
        owner: ubuntu
        group: ubuntu
      loop:
        - setup_hadoop_ecosystem.sh
        - ecosystem_utils.sh
        - run_ecosystem_step.sh
        - cluster_health_full.sh
        - install_core.sh
        - install_processing.sh
        - install_databases.sh
        - install_streaming.sh
        - install_tools.sh

    - name: "Create remote directories for state and logs"
      become: yes
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: ubuntu
        group: ubuntu
      loop:
        - "{{ state_dir }}"
        - "{{ log_dir }}"

    # ===== STEP 1: JAVA & SYSTEM PREPARATION =====
    - name: "STEP 1: Check if Java & System Preparation already completed"
      stat:
        path: "{{ state_dir }}/01_java_system_completed"
      register: step1_status

    - name: "STEP 1: Execute Java & System Preparation"
      command: "{{ script_dir }}/run_ecosystem_step.sh prepare_system"
      register: step1_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step1_result.rc == 0
      when: not step1_status.stat.exists
      timeout: 1800
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        JAVA_VERSION: "{{ java_version }}"

    - name: "STEP 1: Display results"
      debug:
        msg: |
          STEP 1 - Java & System Preparation: {{ 'COMPLETED' if step1_status.stat.exists else ('SUCCESS' if step1_result is defined and step1_result.rc == 0 else 'FAILED') }}

    # ===== STEP 2: CORE HADOOP ECOSYSTEM =====
    - name: "STEP 2: Check if Core Hadoop Ecosystem already completed"
      stat:
        path: "{{ state_dir }}/02_core_hadoop_completed"
      register: step2_status

    - name: "STEP 2: Execute Core Hadoop Ecosystem Installation"
      command: "{{ script_dir }}/run_ecosystem_step.sh install_core_hadoop"
      register: step2_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step2_result.rc == 0
      when: not step2_status.stat.exists
      timeout: 2400
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        HADOOP_VERSION: "{{ hadoop_version }}"
        HIVE_VERSION: "{{ hive_version }}"
        SQOOP_VERSION: "{{ sqoop_version }}"
        FLUME_VERSION: "{{ flume_version }}"
        OOZIE_VERSION: "{{ oozie_version }}"
        HADOOP_HOME: "{{ hadoop_home }}"
        HIVE_HOME: "{{ hive_home }}"
        SQOOP_HOME: "{{ sqoop_home }}"
        FLUME_HOME: "{{ flume_home }}"
        OOZIE_HOME: "{{ oozie_home }}"

    - name: "STEP 2: Display results"
      debug:
        msg: |
          STEP 2 - Core Hadoop Ecosystem: {{ 'COMPLETED' if step2_status.stat.exists else ('SUCCESS' if step2_result is defined and step2_result.rc == 0 else 'FAILED') }}

    # ===== STEP 3: PROCESSING ENGINES =====
    - name: "STEP 3: Check if Processing Engines already completed"
      stat:
        path: "{{ state_dir }}/03_processing_engines_completed"
      register: step3_status

    - name: "STEP 3: Execute Processing Engines Installation"
      command: "{{ script_dir }}/run_ecosystem_step.sh install_processing_engines"
      register: step3_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step3_result.rc == 0
      when: not step3_status.stat.exists
      timeout: 2400
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        SPARK_VERSION: "{{ spark_version }}"
        FLINK_VERSION: "{{ flink_version }}"
        PRESTO_VERSION: "{{ presto_version }}"
        DRILL_VERSION: "{{ drill_version }}"
        MAHOUT_VERSION: "{{ mahout_version }}"
        SPARK_HOME: "{{ spark_home }}"
        FLINK_HOME: "{{ flink_home }}"
        PRESTO_HOME: "{{ presto_home }}"
        DRILL_HOME: "{{ drill_home }}"
        MAHOUT_HOME: "{{ mahout_home }}"

    - name: "STEP 3: Display results"
      debug:
        msg: |
          STEP 3 - Processing Engines: {{ 'COMPLETED' if step3_status.stat.exists else ('SUCCESS' if step3_result is defined and step3_result.rc == 0 else 'FAILED') }}

    # ===== STEP 4: NOSQL DATABASES =====
    - name: "STEP 4: Check if NoSQL Databases already completed"
      stat:
        path: "{{ state_dir }}/04_nosql_databases_completed"
      register: step4_status

    - name: "STEP 4: Execute NoSQL Databases Installation"
      command: "{{ script_dir }}/run_ecosystem_step.sh install_nosql_databases"
      register: step4_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step4_result.rc == 0
      when: not step4_status.stat.exists
      timeout: 2400
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        HBASE_VERSION: "{{ hbase_version }}"
        CASSANDRA_VERSION: "{{ cassandra_version }}"
        MONGODB_VERSION: "{{ mongodb_version }}"
        HBASE_HOME: "{{ hbase_home }}"
        CASSANDRA_HOME: "{{ cassandra_home }}"

    - name: "STEP 4: Display results"
      debug:
        msg: |
          STEP 4 - NoSQL Databases: {{ 'COMPLETED' if step4_status.stat.exists else ('SUCCESS' if step4_result is defined and step4_result.rc == 0 else 'FAILED') }}

    # ===== STEP 5: STREAMING & MESSAGING =====
    - name: "STEP 5: Check if Streaming & Messaging already completed"
      stat:
        path: "{{ state_dir }}/05_streaming_messaging_completed"
      register: step5_status

    - name: "STEP 5: Execute Streaming & Messaging Installation"
      command: "{{ script_dir }}/run_ecosystem_step.sh install_streaming_messaging"
      register: step5_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step5_result.rc == 0
      when: not step5_status.stat.exists
      timeout: 2400
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        KAFKA_VERSION: "{{ kafka_version }}"
        NIFI_VERSION: "{{ nifi_version }}"
        STORM_VERSION: "{{ storm_version }}"
        ZOOKEEPER_VERSION: "{{ zookeeper_version }}"
        KAFKA_HOME: "{{ kafka_home }}"
        NIFI_HOME: "{{ nifi_home }}"
        STORM_HOME: "{{ storm_home }}"
        ZOOKEEPER_HOME: "{{ zookeeper_home }}"

    - name: "STEP 5: Display results"
      debug:
        msg: |
          STEP 5 - Streaming & Messaging: {{ 'COMPLETED' if step5_status.stat.exists else ('SUCCESS' if step5_result is defined and step5_result.rc == 0 else 'FAILED') }}

    # ===== STEP 6: SEARCH & INDEXING =====
    - name: "STEP 6: Check if Search & Indexing already completed"
      stat:
        path: "{{ state_dir }}/06_search_indexing_completed"
      register: step6_status

    - name: "STEP 6: Execute Search & Indexing Installation"
      command: "{{ script_dir }}/run_ecosystem_step.sh install_search_indexing"
      register: step6_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step6_result.rc == 0
      when: not step6_status.stat.exists
      timeout: 1800
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        SOLR_VERSION: "{{ solr_version }}"
        ELASTICSEARCH_VERSION: "{{ elasticsearch_version }}"
        SOLR_HOME: "{{ solr_home }}"
        ELASTICSEARCH_HOME: "{{ elasticsearch_home }}"

    - name: "STEP 6: Display results"
      debug:
        msg: |
          STEP 6 - Search & Indexing: {{ 'COMPLETED' if step6_status.stat.exists else ('SUCCESS' if step6_result is defined and step6_result.rc == 0 else 'FAILED') }}

    # ===== STEP 7: WORKFLOW & ORCHESTRATION =====
    - name: "STEP 7: Check if Workflow & Orchestration already completed"
      stat:
        path: "{{ state_dir }}/07_workflow_orchestration_completed"
      register: step7_status
      when: node_role in ['namenode', 'master']

    - name: "STEP 7: Execute Workflow & Orchestration Installation"
      command: "{{ script_dir }}/run_ecosystem_step.sh install_workflow_orchestration"
      register: step7_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step7_result.rc == 0
      when: 
        - node_role in ['namenode', 'master']
        - not step7_status.stat.exists
      timeout: 1800
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        AIRFLOW_VERSION: "{{ airflow_version }}"

    - name: "STEP 7: Display results"
      debug:
        msg: |
          STEP 7 - Workflow & Orchestration: {{ 'COMPLETED' if step7_status.stat.exists else ('SUCCESS' if step7_result is defined and step7_result.rc == 0 else 'SKIPPED') }}
      when: node_role in ['namenode', 'master']

    # ===== STEP 8: CONFIGURATION =====
    - name: "STEP 8: Check if Configuration already completed"
      stat:
        path: "{{ state_dir }}/08_configuration_completed"
      register: step8_status

    - name: "STEP 8: Execute Configuration"
      command: "{{ script_dir }}/run_ecosystem_step.sh configure_ecosystem"
      register: step8_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step8_result.rc == 0
      when: not step8_status.stat.exists
      timeout: 1200
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        NODE_ROLE: "{{ node_role }}"
        NAMENODE_HOST: "{{ hostvars[namenode_host]['ansible_host'] }}"
        RESOURCEMANAGER_HOST: "{{ hostvars[resourcemanager_host]['ansible_host'] }}"
        HBASE_MASTER_HOST: "{{ hostvars[hbase_master_host]['ansible_host'] }}"

    - name: "STEP 8: Display results"
      debug:
        msg: |
          STEP 8 - Configuration: {{ 'COMPLETED' if step8_status.stat.exists else ('SUCCESS' if step8_result is defined and step8_result.rc == 0 else 'FAILED') }}

    # ===== STEP 9: ROLE-SPECIFIC INITIALIZATION =====
    - name: "STEP 9: Check if Role-specific Initialization already completed"
      stat:
        path: "{{ state_dir }}/09_role_init_completed"
      register: step9_status

    - name: "STEP 9: Execute Role-specific Initialization"
      command: "{{ script_dir }}/run_ecosystem_step.sh initialize_role"
      register: step9_result
      retries: "{{ max_retries }}"
      delay: 30
      until: step9_result.rc == 0
      when: not step9_status.stat.exists
      timeout: 1200
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        MAX_RETRIES: "{{ max_retries }}"
        NODE_ROLE: "{{ node_role }}"
        NAMENODE_HOST: "{{ hostvars[namenode_host]['ansible_host'] }}"

    - name: "STEP 9: Display results"
      debug:
        msg: |
          STEP 9 - Role Initialization: {{ 'COMPLETED' if step9_status.stat.exists else ('SUCCESS' if step9_result is defined and step9_result.rc == 0 else 'FAILED') }}

    # ===== WAIT FOR ECOSYSTEM STABILIZATION =====
    - name: "Wait for ecosystem to stabilize"
      pause:
        seconds: 120
      when: node_role == "namenode"

    # ===== FINAL VERIFICATION =====
    - name: "FINAL: Execute Comprehensive Verification"
      command: "{{ script_dir }}/run_ecosystem_step.sh verify_full_ecosystem"
      register: final_result
      timeout: 600
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        LOG_FILE: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        STATE_DIR: "{{ state_dir }}"
        NODE_ROLE: "{{ node_role }}"

    - name: "FINAL: Display verification results"
      debug:
        msg: |
          Final Ecosystem Verification on {{ inventory_hostname }}: {{ 'SUCCESS' if final_result.rc == 0 else 'FAILED' }}
          Role: {{ node_role }}
          {% if final_result.stdout %}
          Output: {{ final_result.stdout }}
          {% endif %}

    # ===== COPY LOGS =====
    - name: "Copy logs back to local"
      fetch:
        src: "{{ log_dir }}/{{ inventory_hostname }}-setup.log"
        dest: "./logs/{{ inventory_hostname }}-ecosystem-setup.log"
        flat: yes
      ignore_errors: yes

    - name: "Display individual node completion"
      debug:
        msg: |
          ===============================================
          Node Ecosystem Setup Complete: {{ inventory_hostname }}
          ===============================================
          Role: {{ node_role }}
          IP: {{ ansible_host }}
          Status: {{ 'SUCCESS' if final_result.rc == 0 else 'FAILED' }}
          Log: ./logs/{{ inventory_hostname }}-ecosystem-setup.log
          ===============================================

# ===== ECOSYSTEM-WIDE VERIFICATION =====
- name: Final Hadoop Ecosystem Verification and Status
  hosts: hadoop
  become: no
  gather_facts: no
  run_once: true
  vars:
    script_dir: "/home/ubuntu/hadoop-scripts"

  tasks:
    - name: "Final ecosystem verification"
      command: "{{ script_dir }}/cluster_health_full.sh"
      register: final_verification
      timeout: 600
      environment:
        HOME: "/home/ubuntu"
        USER: "ubuntu"
        HADOOP_HOME: "{{ hadoop_home }}"
        SPARK_HOME: "{{ spark_home }}"
        HIVE_HOME: "{{ hive_home }}"
        HBASE_HOME: "{{ hbase_home }}"
        KAFKA_HOME: "{{ kafka_home }}"
        FLINK_HOME: "{{ flink_home }}"
      delegate_to: "{{ groups['namenode'][0] }}"
      ignore_errors: yes

    - name: "Generate comprehensive configuration files"
      template:
        src: "templates/{{ item.src }}"
        dest: "{{ item.dest }}"
        mode: "{{ item.mode | default('0644') }}"
      loop:
        - { src: "hadoop-ecosystem-info.j2", dest: "./hadoop-ecosystem-info.yml" }
        - { src: "start-full-ecosystem.sh.j2", dest: "./scripts/start-full-ecosystem.sh", mode: "0755" }
        - { src: "stop-full-ecosystem.sh.j2", dest: "./scripts/stop-full-ecosystem.sh", mode: "0755" }
        - { src: "ecosystem-health-check.sh.j2", dest: "./scripts/ecosystem-health-check.sh", mode: "0755" }
        - { src: "ecosystem-summary.md.j2", dest: "./hadoop-ecosystem-complete.md" }
        - { src: "service-urls.j2", dest: "./service-urls.txt" }
      delegate_to: localhost
      become: no

    - name: "Display final success message"
      debug:
        msg: |
          ===============================================
          üéâ COMPLETE HADOOP ECOSYSTEM SETUP FINISHED! üéâ
          ===============================================

          Your comprehensive big data ecosystem is ready!

          üìä INSTALLED COMPONENTS:
          ‚úÖ Hadoop (HDFS + YARN)    ‚úÖ Spark              ‚úÖ Flink
          ‚úÖ Hive                     ‚úÖ HBase              ‚úÖ Cassandra
          ‚úÖ Kafka                    ‚úÖ Zookeeper          ‚úÖ NiFi
          ‚úÖ Storm                    ‚úÖ Presto             ‚úÖ Drill
          ‚úÖ Solr                     ‚úÖ Elasticsearch      ‚úÖ MongoDB
          ‚úÖ Sqoop                    ‚úÖ Flume              ‚úÖ Oozie
          ‚úÖ Mahout                   ‚úÖ Airflow

          üåê ACCESS POINTS:
          - NameNode: http://{{ hostvars[groups['namenode'][0]]['ansible_host'] }}:9870
          - YARN: http://{{ hostvars[groups['namenode'][0]]['ansible_host'] }}:8088
          - Spark: http://{{ hostvars[groups['namenode'][0]]['ansible_host'] }}:8080
          - HBase: http://{{ hostvars[groups['namenode'][0]]['ansible_host'] }}:16010
          
          üìÅ FILES CREATED:
          - hadoop-ecosystem-info.yml
          - scripts/start-full-ecosystem.sh
          - scripts/stop-full-ecosystem.sh
          - scripts/ecosystem-health-check.sh
          - service-urls.txt
          - hadoop-ecosystem-complete.md

          All logs saved to ./logs/ directory
          ===============================================
